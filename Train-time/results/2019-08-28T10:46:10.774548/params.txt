batch_size = 128
alpha = 0.1
epsilon = 0.0001
num_units = 300
n_hidden_layers = 1
num_epochs = 300
dropout_in = 0.2
dropout_hidden = 0.5
activation = lasagne.nonlinearities.tanh
binary = False
stochastic = False
H = 1.0
W_LR_scale = Glorot
LR_start = 0.01
LR_fin = 1e-05
LR_decay = 0.9772372209558107
save_path = None
shuffle_parts = 1
noise = u
nalpha = 0
train_set_size = 10000
validation_set_size = 10000
test_set_size = 10000
