batch_size = 128
alpha = 0.1
epsilon = 0.0001
num_units = 300
n_hidden_layers = 2
num_epochs = 500
dropout_in = 0.2
dropout_hidden = 0.5
activation = lasagne.nonlinearities.tanh
binary = False
stochastic = False
H = 1.0
W_LR_scale = Glorot
LR_start = 0.005
LR_fin = 5e-07
LR_decay = 0.9817479430199844
save_path = None
shuffle_parts = 1
noise = u
nalpha = 70
train_set_size = 710000
validation_set_size = 10000
test_set_size = 10000
