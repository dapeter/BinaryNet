batch_size = 128
alpha = 0.1
epsilon = 0.0001
num_units = 1024
n_hidden_layers = 1
num_epochs = 200
dropout_in = 0.2
dropout_hidden = 0.5
stochastic = False
H = 1.0
W_LR_scale = Glorot
LR_start = 0.001
LR_fin = 0.0001
LR_decay = 0.9885530946569389
train_set_size = 10000
shuffle_parts = 1
